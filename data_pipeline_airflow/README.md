## Data Pipelines - Airfflow

### Introduction 

<i>Sparkify</i> is a startup that owns a new music streaming app.
They've collected some data about songs and user activity on this app. All their data resides in S3, in a directory of JSON logs on user activity on the app, as well as a directory with JSON metadata on the songs in their app.

### Objectives

<i>Sparkify</i> needs to create high grade data pipelines that are dynamic and built from reusable tasks, can be monitored, and allow easy backfills. They have also noted that the data quality plays a big part when analyses are executed on top the data warehouse and want to run tests against their datasets after the ETL steps have been executed to catch any discrepancies in the datasets.

### Datasets

- **Songs**: is a subset of real data from [Million Song Dataset](http://millionsongdataset.com/). The files reside in s3://udacity-dend/song_data and looks like this:

```
 {"num_songs": 1, "artist_id": "ARJIE2Y1187B994AB7", "artist_latitude": null, "artist_longitude": null, "artist_location": "", "artist_name": "Line Renaud", "song_id": "SOUPIRU12A6D4FA1E1", "title": "Der Kleine Dompfaff", "duration": 152.92036, "year": 0} </code>
 ```

- **Logs**: generated by [event simulator](https://github.com/Interana/eventsim). The files reside in s3://udacity-dend/log_data and looks like this:

```
 {"artist":"Girl Talk","auth":"Logged In","firstName":"Kaylee","gender":"F","itemInSession":8,"lastName":"Summers","length":160.15628,"level":"free","location":"Phoenix-Mesa-Scottsdale, AZ","method":"PUT","page":"NextSong","registration":1540344794796.0,"sessionId":139,"song":"Once again","status":200,"ts":1541107734796,"userAgent":"\"Mozilla\/5.0 (Windows NT 6.1; WOW64) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/35.0.1916.153 Safari\/537.36\"","userId":"8"}
 ```

 - **There's also a kind of metadata of logs, with all columns in lowercase:** s3://udacity-dend/log_json_path.json
